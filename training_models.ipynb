{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import division\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchsummary import summary\n",
    "\n",
    "# Numpy, scipy, scikit-image, spectral\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import sklearn.model_selection\n",
    "from skimage import io\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "# import visdom\n",
    "\n",
    "import os\n",
    "from utils import (\n",
    "    convert_to_color_,\n",
    "    convert_from_color_,\n",
    "    get_device,\n",
    "    # metrics,\n",
    "    # display_dataset,\n",
    "    # display_predictions,\n",
    "    # explore_spectrums,\n",
    "    # plot_spectrums,\n",
    "    # sample_gt,\n",
    "    # build_dataset,\n",
    "    # show_results,\n",
    "    # compute_imf_weights,\n",
    ")\n",
    "# from datasets import get_dataset, HyperX, open_file, DATASETS_CONFIG\n",
    "from datasets import load_dataset\n",
    "from models import get_model #, train, test, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ CUDA was requested but is not available! Computation will go on CPU. /!\\\n"
     ]
    }
   ],
   "source": [
    "CUDA_DEVICE = get_device(0)\n",
    "\n",
    "# % of training samples\n",
    "SAMPLE_PERCENTAGE = 10\n",
    "# Data augmentation ?\n",
    "# FLIP_AUGMENTATION = args.flip_augmentation\n",
    "# RADIATION_AUGMENTATION = args.radiation_augmentation\n",
    "# MIXTURE_AUGMENTATION = args.mixture_augmentation\n",
    "# Dataset name\n",
    "DATASET = 'Salinas'\n",
    "# Model name\n",
    "MODEL = 'hamida'\n",
    "# Number of runs (for cross-validation)\n",
    "N_RUNS = 1\n",
    "# Spatial context size (number of neighbours in each spatial direction)\n",
    "PATCH_SIZE = 5\n",
    "# Add some visualization of the spectra ?\n",
    "# DATAVIZ = args.with_exploration\n",
    "\n",
    "# Target folder to store/download/load the datasets\n",
    "FOLDER = 'Datasets\\Raw\\Salinas'\n",
    "# Number of epochs to run\n",
    "EPOCH = 5\n",
    "# Sampling mode, e.g random sampling\n",
    "SAMPLING_MODE = 'random'\n",
    "# Pre-computed weights to restore\n",
    "CHECKPOINT = None\n",
    "# Learning rate for the SGD\n",
    "LEARNING_RATE = 0.01\n",
    "# Automated class balancing\n",
    "CLASS_BALANCING = False\n",
    "# Training ground truth file\n",
    "# TRAIN_GT = args.train_set\n",
    "# Testing ground truth file\n",
    "# TEST_GT = args.test_set\n",
    "TEST_STRIDE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df, img, gt, LABEL_VALUES, IGNORED_LABELS, RGB_BANDS, palette = load_dataset(dataset_name='Salinas',\n",
    "                                                                         dr_method='PCA',\n",
    "                                                                         n_components=8)\n",
    "# Number of classes\n",
    "N_CLASSES = len(LABEL_VALUES)\n",
    "# Number of bands (last dimension of the image tensor)\n",
    "N_BANDS = img.shape[-1]\n",
    "\n",
    "if palette is None:\n",
    "    # Generate color palette\n",
    "    palette = {0: (0, 0, 0)}\n",
    "    for k, color in enumerate(sns.color_palette(\"hls\", len(LABEL_VALUES) - 1)):\n",
    "        palette[k + 1] = tuple(np.asarray(255 * np.array(color), dtype=\"uint8\"))\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "\n",
    "def convert_to_color(x):\n",
    "    return convert_to_color_(x, palette=palette)\n",
    "\n",
    "\n",
    "def convert_from_color(x):\n",
    "    return convert_from_color_(x, palette=invert_palette)\n",
    "\n",
    "color_gt = convert_to_color(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5394 samples selected (over 54129)\n",
      "Running an experiment with the hamida model run 1/1\n",
      "Network :\n",
      "(0, PC-1    -6136.415770\n",
      "PC-2    -4385.651601\n",
      "PC-3      628.426690\n",
      "PC-4     -302.089387\n",
      "PC-5       -7.164320\n",
      "PC-6       48.222012\n",
      "PC-7     -129.801973\n",
      "PC-8      -28.045864\n",
      "class       0.000000\n",
      "Name: 0, dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\envs\\dslab1\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value after * must be an iterable, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCUDA_DEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# We would like to use device=hyperparams['device'] altough we have\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# to wait for torchsummary to be fixed first.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Split train set in train/val\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\envs\\dslab1\\Lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\envs\\dslab1\\Lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39min_size)\u001b[38;5;241m.\u001b[39mtype(dtype) \u001b[38;5;28;01mfor\u001b[39;00m in_size \u001b[38;5;129;01min\u001b[39;00m input_size]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[1;31mTypeError\u001b[0m: Value after * must be an iterable, not float"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "results = []\n",
    "# run the experiment several times\n",
    "for run in range(N_RUNS):\n",
    "    X_train, X_test, train_gt, test_gt = train_test_split(img, gt, test_size=1-SAMPLE_PERCENTAGE/100)\n",
    "    print(\n",
    "        \"{} samples selected (over {})\".format(\n",
    "            np.count_nonzero(train_gt), np.count_nonzero(gt)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Running an experiment with the {} model\".format(MODEL),\n",
    "        \"run {}/{}\".format(run + 1, N_RUNS),\n",
    "    )\n",
    "    \n",
    "    if MODEL == 'nearest':\n",
    "        #...\n",
    "        print()\n",
    "    else:\n",
    "        # if CLASS_BALANCING:\n",
    "        #     weights = compute_imf_weights(train_gt, N_CLASSES, IGNORED_LABELS)\n",
    "        #     hyperparams[\"weights\"] = torch.from_numpy(weights)\n",
    "        # Neural network\n",
    "        # model, optimizer, loss, hyperparams = get_model(MODEL, **hyperparams)\n",
    "\n",
    "        BATCH_SIZE=100\n",
    "\n",
    "        model, optimizer, loss = get_model(MODEL, device=CUDA_DEVICE, n_classes=N_CLASSES, n_bands=N_BANDS, \n",
    "                                           ignored_labels=IGNORED_LABELS, patch_size=PATCH_SIZE, dropout=False, \n",
    "                                           lr=LEARNING_RATE, epoch=EPOCH, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        train_loader = data.DataLoader(df, \n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        shuffle=True)\n",
    "        \n",
    "        print(\"Network :\")\n",
    "        with torch.no_grad():\n",
    "            for input in df.iterrows():\n",
    "                break\n",
    "            print(input)\n",
    "            summary(model.to(CUDA_DEVICE), input[1])\n",
    "            # We would like to use device=hyperparams['device'] altough we have\n",
    "            # to wait for torchsummary to be fixed first.\n",
    "        # Split train set in train/val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].shape[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
